# Chapter 02: ì„¤ì¹˜ ê°€ì´ë“œ

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 30ë¶„

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ì±•í„°ë¥¼ ë§ˆì¹˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- âœ… Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- âœ… Python í™˜ê²½ êµ¬ì„±
- âœ… í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
- âœ… ì²« ë²ˆì§¸ ë¶„ì„ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰

---

## ğŸ“‹ ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜

| í•­ëª© | ìš”êµ¬ì‚¬í•­ | í™•ì¸ ë°©ë²• |
|------|----------|-----------|
| **Python** | 3.12 ì´ìƒ | `python --version` |
| **Git** | 2.0 ì´ìƒ | `git --version` |
| **ë””ìŠ¤í¬ ê³µê°„** | 20GB ì´ìƒ | `df -h` |
| **RAM** | 8GB ì´ìƒ | - |

### ê¶Œì¥

| í•­ëª© | ê¶Œì¥ì‚¬í•­ | ì´ìœ  |
|------|----------|------|
| **GPU** | NVIDIA GPU | ì¶”ë¡  ì†ë„ 10ë°°+ ë¹ ë¦„ |
| **RAM** | 16GB ì´ìƒ | 33B ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš© |
| **ë””ìŠ¤í¬** | SSD | ëª¨ë¸ ë¡œë”© ì†ë„ ë¹ ë¦„ |

---

## Step 1: Python í™˜ê²½ í™•ì¸

### 1.1 Python ë²„ì „ í™•ì¸

```bash
python --version
# ë˜ëŠ”
python3 --version
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
Python 3.12.0 (ë˜ëŠ” ê·¸ ì´ìƒ)
```

**ë§Œì•½ 3.12 ë¯¸ë§Œì´ë¼ë©´**:

```bash
# Ubuntu/Debian
sudo apt install python3.12

# macOS (Homebrew ì‚¬ìš©)
brew install python@3.12

# Windows
# python.orgì—ì„œ 3.12+ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ
```

### 1.2 pip ì—…ê·¸ë ˆì´ë“œ

```bash
python -m pip install --upgrade pip
```

---

## Step 2: Ollama ì„¤ì¹˜

### 2.1 Ollama ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜

**Linux & macOS**:

```bash
curl https://ollama.ai/install.sh | sh
```

**Windows**:
1. [Ollama ê³µì‹ ì‚¬ì´íŠ¸](https://ollama.ai/download) ë°©ë¬¸
2. Windows ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ
3. ì„¤ì¹˜ ì‹¤í–‰

### 2.2 Ollama ì„¤ì¹˜ í™•ì¸

```bash
ollama --version
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
ollama version is 0.1.x
```

### 2.3 Ollama ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# Linux/macOS (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
ollama serve &

# Windows
# ì„¤ì¹˜í•˜ë©´ ìë™ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì‹œì‘ë¨
```

**í™•ì¸**:
```bash
# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
ollama list
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
NAME                    ID              SIZE    MODIFIED
(ì²˜ìŒì—ëŠ” ë¹„ì–´ìˆìŒ)
```

---

## Step 3: DeepSeek-Coder ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

### 3.1 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

**ì¤‘ìš”**: ì´ ë‹¨ê³„ëŠ” **18GB ë‹¤ìš´ë¡œë“œ**ì´ë¯€ë¡œ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤ (10-30ë¶„).

```bash
ollama pull deepseek-coder:33b-instruct
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
pulling manifest
pulling 8934d96d3f08... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 18 GB
pulling 8c17c2ebb0ea... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 7.0 KB
pulling 590d74a5569b... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 6.0 KB
pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  96 B
pulling 6a27a0d70ff0... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 485 B
verifying sha256 digest
writing manifest
success
```

### 3.2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸

```bash
ollama list
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
NAME                            ID              SIZE    MODIFIED
deepseek-coder:33b-instruct     abc123def456    18 GB   2 minutes ago
```

### 3.3 ëª¨ë¸ í…ŒìŠ¤íŠ¸

```bash
ollama run deepseek-coder:33b-instruct "What is a memory leak in C++?"
```

**ê¸°ëŒ€**: LLMì´ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ë©´ ì„±ê³µ!

---

## Step 4: í”„ë¡œì íŠ¸ ì„¤ì¹˜

### 4.1 ì €ì¥ì†Œ í´ë¡ 

```bash
# ì €ì¥ì†Œ í´ë¡  (ì‹¤ì œ URLë¡œ ë³€ê²½ í•„ìš”)
git clone <repository-url>
cd llm-code-reviewer

# ë˜ëŠ” ì´ë¯¸ í´ë¡ í•œ ê²½ìš°
cd /path/to/llm-code-reviewer
```

### 4.2 ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)

**ê°€ìƒí™˜ê²½ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ **:
- í”„ë¡œì íŠ¸ë³„ ì˜ì¡´ì„± ê²©ë¦¬
- ì‹œìŠ¤í…œ Python ë³´í˜¸
- ë²„ì „ ì¶©ëŒ ë°©ì§€

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Linux/macOS:
source venv/bin/activate

# Windows (PowerShell):
venv\Scripts\Activate.ps1

# Windows (CMD):
venv\Scripts\activate.bat
```

**í™œì„±í™” í™•ì¸**:
```bash
# í”„ë¡¬í”„íŠ¸ ì•ì— (venv)ê°€ ë³´ì—¬ì•¼ í•¨
(venv) user@machine:~/llm-code-reviewer$
```

### 4.3 ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜ (ìˆ˜ì • ì‚¬í•­ì´ ì¦‰ì‹œ ë°˜ì˜ë¨)
pip install -e .
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Installing collected packages: ...
Successfully installed ollama-0.1.0 pydantic-2.0.0 ...
```

### 4.4 ì„¤ì¹˜ í™•ì¸

```bash
# Pythonì—ì„œ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
python -c "from framework.ollama_client import OllamaClient; print('âœ… Import successful')"
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
âœ… Import successful
```

---

## Step 5: ì²« ë²ˆì§¸ ë¶„ì„ ì‹¤í–‰

### 5.1 í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¤€ë¹„

ê°„ë‹¨í•œ ë²„ê·¸ê°€ ìˆëŠ” C++ íŒŒì¼ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤:

```bash
cat > test_memory_leak.cpp << 'EOF'
#include <iostream>

int main() {
    int* ptr = new int(10);  // ë©”ëª¨ë¦¬ í• ë‹¹
    std::cout << *ptr << std::endl;
    return 0;  // delete ì—†ìŒ! (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜)
}
EOF
```

### 5.2 ë¶„ì„ ì‹¤í–‰

```bash
python -m cli.main analyze file test_memory_leak.cpp
```

**ê¸°ëŒ€ ì¶œë ¥**:
```
Analyzing file: test_memory_leak.cpp
Model: deepseek-coder:33b-instruct

Found 1 issue(s):

â— Line 4 [memory-safety] Memory leak - dynamically allocated pointer never deleted
  Pointer allocated with 'new' on line 4 but there is no corresponding 'delete' statement.
  This causes a memory leak on every execution.
```

**âœ… ì„±ê³µ!** LLMì´ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ì •í™•íˆ íƒì§€í–ˆìŠµë‹ˆë‹¤!

---

## Step 6: ì„¤ì¹˜ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤:

### 6.1 ìë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```bash
cat > verify_installation.sh << 'EOF'
#!/bin/bash

echo "=== LLM Code Reviewer ì„¤ì¹˜ ê²€ì¦ ==="
echo ""

# Python ë²„ì „ í™•ì¸
echo "1. Python ë²„ì „ í™•ì¸..."
python --version | grep -q "3.1[2-9]" && echo "  âœ… Python 3.12+" || echo "  âŒ Python 3.12+ í•„ìš”"

# Ollama ì„¤ì¹˜ í™•ì¸
echo "2. Ollama ì„¤ì¹˜ í™•ì¸..."
ollama --version > /dev/null 2>&1 && echo "  âœ… Ollama ì„¤ì¹˜ë¨" || echo "  âŒ Ollama ì„¤ì¹˜ í•„ìš”"

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸
echo "3. DeepSeek-Coder ëª¨ë¸ í™•ì¸..."
ollama list | grep -q "deepseek-coder:33b-instruct" && echo "  âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¨" || echo "  âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”"

# Python íŒ¨í‚¤ì§€ í™•ì¸
echo "4. Python íŒ¨í‚¤ì§€ í™•ì¸..."
python -c "from framework.ollama_client import OllamaClient" 2>/dev/null && echo "  âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨" || echo "  âŒ pip install -e . ì‹¤í–‰ í•„ìš”"

# CLI ëª…ë ¹ì–´ í™•ì¸
echo "5. CLI ëª…ë ¹ì–´ í™•ì¸..."
python -m cli.main --help > /dev/null 2>&1 && echo "  âœ… CLI ì‘ë™í•¨" || echo "  âŒ CLI ì˜¤ë¥˜"

echo ""
echo "=== ê²€ì¦ ì™„ë£Œ ==="
EOF

chmod +x verify_installation.sh
./verify_installation.sh
```

### 6.2 ìˆ˜ë™ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Python 3.12+ ì„¤ì¹˜ë¨
- [ ] Ollama ì„¤ì¹˜ë¨ ë° ì‹¤í–‰ ì¤‘
- [ ] DeepSeek-Coder 33B ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¨
- [ ] ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”ë¨
- [ ] `pip install -e .` ì„±ê³µ
- [ ] ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ì²« ë²ˆì§¸ ë¶„ì„ ì‹¤í–‰ ì„±ê³µ

**ëª¨ë‘ ì²´í¬ë˜ì—ˆë‚˜ìš”?** ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰

---

## ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: "ollama: command not found"

**ì›ì¸**: Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ PATHì— ì—†ìŒ

**í•´ê²°**:
```bash
# ì¬ì„¤ì¹˜
curl https://ollama.ai/install.sh | sh

# PATH í™•ì¸
echo $PATH | grep -q ollama || echo "Ollama not in PATH"

# ìˆ˜ë™ìœ¼ë¡œ PATH ì¶”ê°€ (í•„ìš”ì‹œ)
export PATH=$PATH:/usr/local/bin
```

---

### ë¬¸ì œ 2: "ModuleNotFoundError: No module named 'framework'"

**ì›ì¸**: `pip install -e .` ì‹¤í–‰ ì•ˆ í–ˆê±°ë‚˜ ê°€ìƒí™˜ê²½ í™œì„±í™” ì•ˆ ë¨

**í•´ê²°**:
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
which python
# /path/to/venv/bin/python ì´ì–´ì•¼ í•¨

# ì¬ì„¤ì¹˜
pip install -e .
```

---

### ë¬¸ì œ 3: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼ ë˜ëŠ” ì‹¤íŒ¨

**ì›ì¸**: ë„¤íŠ¸ì›Œí¬ ëŠë¦¼ ë˜ëŠ” ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

**í•´ê²°**:
```bash
# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
df -h

# ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„
ollama pull deepseek-coder:33b-instruct

# ë” ì‘ì€ ëª¨ë¸ ì‹œë„ (í…ŒìŠ¤íŠ¸ìš©)
ollama pull qwen2.5-coder:14b
```

---

### ë¬¸ì œ 4: ë©”ëª¨ë¦¬ ë¶€ì¡± (Out of Memory)

**ì¦ìƒ**:
```
Error: model requires more memory than available
```

**ì›ì¸**: 33B ëª¨ë¸ì€ ìµœì†Œ 16GB RAM í•„ìš”

**í•´ê²°**:

**ì˜µì…˜ 1**: ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
```bash
# 14B ëª¨ë¸ (8GB RAMìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥)
ollama pull qwen2.5-coder:14b

# ë¶„ì„ ì‹œ ëª¨ë¸ ì§€ì •
python -m cli.main analyze file test.cpp --model qwen2.5-coder:14b
```

**ì˜µì…˜ 2**: GPU ì‚¬ìš© (VRAM í™œìš©)
```bash
# GPU í™•ì¸
nvidia-smi

# Ollamaê°€ ìë™ìœ¼ë¡œ GPU ê°ì§€
```

**ì˜µì…˜ 3**: Swap ë©”ëª¨ë¦¬ ëŠ˜ë¦¬ê¸° (Linux)
```bash
# 16GB swap ìƒì„±
sudo fallocate -l 16G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

---

## ë‹¤ìŒ ë‹¨ê³„

ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë‹ˆ ì´ì œ í”„ë¡œì íŠ¸ë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤!

### ì˜µì…˜ 1: ë°”ë¡œ ì‹¤ìŠµ ì‹œì‘
ğŸ‘‰ [Chapter 05: ì‹¤ìŠµ ê°€ì´ë“œ](05-usage-guide.md)ë¡œ ê±´ë„ˆë›°ê¸°

### ì˜µì…˜ 2: ì•„í‚¤í…ì²˜ ë¨¼ì € ì´í•´
ğŸ‘‰ [Chapter 03: ì•„í‚¤í…ì²˜ ìƒì„¸](03-architecture.md)ë¡œ ì´ë™

### ì˜µì…˜ 3: í”„ë¡¬í”„íŒ… ê¸°ë²• í•™ìŠµ
ğŸ‘‰ [Chapter 04: í”„ë¡¬í”„íŒ… ê¸°ë²•](04-prompting-techniques.md)ë¡œ ì´ë™

---

## ğŸ’¡ í•µì‹¬ ìš”ì•½

### ì„¤ì¹˜ ë‹¨ê³„ ìš”ì•½

```mermaid
graph TB
    Start[ì‹œì‘]
    Start --> Python[Python 3.12+ í™•ì¸]
    Python --> Ollama[Ollama ì„¤ì¹˜]
    Ollama --> Model[DeepSeek-Coder<br/>ë‹¤ìš´ë¡œë“œ 18GB]
    Model --> Venv[ê°€ìƒí™˜ê²½ ìƒì„±]
    Venv --> PipInstall[pip install -e .]
    PipInstall --> Test[ì²« ë¶„ì„ ì‹¤í–‰]
    Test --> Done[ì™„ë£Œ!]

    style Start fill:#1a237e
    style Done fill:#4caf50
```

### ì¤‘ìš” ëª…ë ¹ì–´

```bash
# 1. Ollama ì„¤ì¹˜
curl https://ollama.ai/install.sh | sh

# 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull deepseek-coder:33b-instruct

# 3. í”„ë¡œì íŠ¸ ì„¤ì¹˜
git clone <repo-url>
cd llm-code-reviewer
python -m venv venv
source venv/bin/activate
pip install -e .

# 4. ë¶„ì„ ì‹¤í–‰
python -m cli.main analyze file <your-file.cpp>
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Ollama ê³µì‹ ë¬¸ì„œ](https://ollama.ai/docs)
- [DeepSeek-Coder ëª¨ë¸ ì •ë³´](https://ollama.ai/library/deepseek-coder)
- [Python ê°€ìƒí™˜ê²½ ê°€ì´ë“œ](https://docs.python.org/3/tutorial/venv.html)

---

**ë‹¤ìŒ**: [Chapter 03: ì•„í‚¤í…ì²˜ ìƒì„¸](03-architecture.md) ë˜ëŠ” [Chapter 05: ì‹¤ìŠµ ê°€ì´ë“œ](05-usage-guide.md) â†’

**ì´ì „**: [Chapter 01: í”„ë¡œì íŠ¸ ì†Œê°œ](01-introduction.md) â†
