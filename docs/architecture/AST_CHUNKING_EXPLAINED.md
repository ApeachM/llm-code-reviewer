# AST-Based Chunking: ìƒì„¸ ì„¤ëª…

## ê°œìš”

AST(Abstract Syntax Tree) ê¸°ë°˜ chunkingì€ ëŒ€ìš©ëŸ‰ íŒŒì¼(300+ lines)ì„ ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ LLMì´ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

---

## ğŸ”„ ì „ì²´ í”„ë¡œì„¸ìŠ¤

```mermaid
graph TB
    subgraph "1. Input"
        A[Large C++ File<br/>1000+ lines]
    end

    subgraph "2. Parse"
        B[tree-sitter Parser]
        C[AST Tree]
    end

    subgraph "3. Extract"
        D[Extract Context<br/>#includes, usings]
        E[Find Functions/Classes<br/>function_definition<br/>class_specifier]
    end

    subgraph "4. Create Chunks"
        F[Chunk 1: Function A<br/>Context + Code]
        G[Chunk 2: Class B<br/>Context + Code]
        H[Chunk 3: Function C<br/>Context + Code]
    end

    subgraph "5. Analyze"
        I[LLM Analysis<br/>Parallel Processing]
    end

    subgraph "6. Merge"
        J[Result Merger<br/>Adjust Line Numbers<br/>Deduplicate]
        K[Final Report]
    end

    A --> B
    B --> C
    C --> D
    C --> E
    D --> F
    D --> G
    D --> H
    E --> F
    E --> G
    E --> H
    F --> I
    G --> I
    H --> I
    I --> J
    J --> K
```

---

## ğŸ“‹ Step-by-Step ì˜ˆì œ

### Step 1: ì›ë³¸ íŒŒì¼

```cpp
// sample.cpp (30 lines)
#include <iostream>
#include <vector>
using namespace std;

class Calculator {
private:
    int value;

public:
    Calculator(int v) : value(v) {}

    int add(int x) {
        return value + x;
    }

    int multiply(int x) {
        return value * x;
    }
};

void helperFunction() {
    cout << "Helper" << endl;
}

int main() {
    Calculator calc(10);
    cout << calc.add(5) << endl;
    return 0;
}
```

---

### Step 2: tree-sitter Parsing

**tree-sitterê°€ í•˜ëŠ” ì¼:**
1. C++ ì½”ë“œë¥¼ ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ì½ìŒ
2. ë¬¸ë²• ê·œì¹™ì— ë”°ë¼ AST ìƒì„±
3. ê° ë…¸ë“œëŠ” íƒ€ì…ê³¼ ìœ„ì¹˜ ì •ë³´ë¥¼ ê°€ì§

**ìƒì„±ëœ AST (ë‹¨ìˆœí™”):**
```
root_node
â”œâ”€â”€ preproc_include (#include <iostream>)   [lines 1-1]
â”œâ”€â”€ preproc_include (#include <vector>)     [lines 2-2]
â”œâ”€â”€ using_declaration (using namespace std) [lines 3-3]
â”œâ”€â”€ class_specifier (Calculator)            [lines 5-19]
â”‚   â”œâ”€â”€ identifier (Calculator)
â”‚   â”œâ”€â”€ field_declaration_list
â”‚   â”‚   â”œâ”€â”€ function_definition (Constructor)
â”‚   â”‚   â”œâ”€â”€ function_definition (add)
â”‚   â”‚   â””â”€â”€ function_definition (multiply)
â”œâ”€â”€ function_definition (helperFunction)    [lines 21-23]
â””â”€â”€ function_definition (main)              [lines 25-29]
```

---

### Step 3: Context ì¶”ì¶œ

**ì½”ë“œ (chunker.py:122-139):**
```python
def _extract_file_context(self, tree, code_text: str) -> str:
    context_lines = []

    for node in tree.root_node.children:
        if node.type in ['preproc_include', 'using_declaration',
                        'namespace_alias_definition']:
            start_byte = node.start_byte
            end_byte = node.end_byte
            context_lines.append(code_text[start_byte:end_byte])

    return '\n'.join(context_lines)
```

**ì¶”ì¶œëœ Context:**
```cpp
#include <iostream>
#include <vector>
using namespace std;
```

ì´ contextëŠ” **ëª¨ë“  chunkì— prepend**ë©ë‹ˆë‹¤.

---

### Step 4: Chunk ìƒì„±

**Chunk 1: Calculator í´ë˜ìŠ¤**

```python
Chunk(
    chunk_id="sample.cpp:Calculator:5-19",
    file_path=Path("sample.cpp"),
    start_line=5,    # Original file line number
    end_line=19,
    code="""class Calculator {
private:
    int value;

public:
    Calculator(int v) : value(v) {}

    int add(int x) {
        return value + x;
    }

    int multiply(int x) {
        return value * x;
    }
}""",
    context="""#include <iostream>
#include <vector>
using namespace std;""",
    metadata={'node_type': 'class_specifier', 'node_name': 'Calculator'}
)
```

**Chunk 2: helperFunction**

```python
Chunk(
    chunk_id="sample.cpp:helperFunction:21-23",
    file_path=Path("sample.cpp"),
    start_line=21,
    end_line=23,
    code="""void helperFunction() {
    cout << "Helper" << endl;
}""",
    context="""#include <iostream>
#include <vector>
using namespace std;""",
    metadata={'node_type': 'function_definition', 'node_name': 'helperFunction'}
)
```

**Chunk 3: main í•¨ìˆ˜**

```python
Chunk(
    chunk_id="sample.cpp:main:25-29",
    file_path=Path("sample.cpp"),
    start_line=25,
    end_line=29,
    code="""int main() {
    Calculator calc(10);
    cout << calc.add(5) << endl;
    return 0;
}""",
    context="""#include <iostream>
#include <vector>
using namespace std;""",
    metadata={'node_type': 'function_definition', 'node_name': 'main'}
)
```

---

### Step 5: LLM ì…ë ¥ ìƒì„±

**ChunkAnalyzerê°€ í•˜ëŠ” ì¼ (chunk_analyzer.py:66-85):**

```python
def _build_analysis_code(self, chunk: Chunk) -> str:
    if chunk.context:
        return f"{chunk.context}\n\n{chunk.code}"
    else:
        return chunk.code
```

**Chunk 1ì— ëŒ€í•œ ì‹¤ì œ LLM ì…ë ¥:**

```cpp
#include <iostream>
#include <vector>
using namespace std;

class Calculator {
private:
    int value;

public:
    Calculator(int v) : value(v) {}

    int add(int x) {
        return value + x;
    }

    int multiply(int x) {
        return value * x;
    }
}
```

ì´ ì½”ë“œê°€ Few-shot promptì™€ í•¨ê»˜ LLMì— ì „ì†¡ë©ë‹ˆë‹¤.

---

### Step 6: ë¼ì¸ ë²ˆí˜¸ ì¡°ì •

**ë¬¸ì œ:**
- LLMì€ "context + chunk" ì½”ë“œë¥¼ ë¶„ì„
- Contextê°€ 5ì¤„ì´ê³ , chunkê°€ line 5ë¶€í„° ì‹œì‘
- LLMì´ "line 10"ì—ì„œ ì´ìŠˆë¥¼ ë°œê²¬í–ˆë‹¤ê³  í•˜ë©´?

**í•´ê²° (chunk_analyzer.py:87-132):**

```python
def _adjust_line_numbers(self, result: AnalysisResult, chunk: Chunk) -> AnalysisResult:
    context_lines = len(chunk.context.split('\n')) if chunk.context else 0

    adjusted_issues = []
    for issue in result.issues:
        # LLM reported line 10 in (context + chunk)
        # Context = 5 lines
        # Chunk starts at file line 5
        # Actual line = 5 + (10 - 5 - 1) = 9

        chunk_relative_line = issue.line - context_lines - 1
        actual_line = chunk.start_line + chunk_relative_line

        adjusted_issue = Issue(
            line=actual_line,  # Adjusted to file coordinates
            category=issue.category,
            severity=issue.severity,
            description=issue.description,
            reasoning=issue.reasoning
        )
        adjusted_issues.append(adjusted_issue)

    result.issues = adjusted_issues
    return result
```

**ì˜ˆì œ:**
- Context: 5 lines
- Chunk starts: line 5
- LLM reports issue at line 10 (in context+chunk)
- Adjusted: `5 + (10 - 5 - 1) = 9` âœ…

---

### Step 7: ê²°ê³¼ ë³‘í•© & ì¤‘ë³µ ì œê±°

**ResultMerger (result_merger.py):**

```python
def merge_results(self, chunk_results: List[AnalysisResult]) -> AnalysisResult:
    all_issues = []

    for result in chunk_results:
        all_issues.extend(result.issues)

    # Deduplicate by (line, category)
    unique_issues = {}
    for issue in all_issues:
        key = (issue.line, issue.category)
        if key not in unique_issues:
            unique_issues[key] = issue
        else:
            # Keep higher severity
            if issue.severity == 'critical':
                unique_issues[key] = issue

    return AnalysisResult(
        issues=list(unique_issues.values()),
        metadata={'chunks_analyzed': len(chunk_results)}
    )
```

**ì¤‘ë³µ ì œê±° ì˜ˆì‹œ:**
- Chunk 1: "Line 10, memory-safety, critical"
- Chunk 2: "Line 10, memory-safety, warning" (overlapping context)
- **ê²°ê³¼:** Line 10, memory-safety, critical âœ… (critical ìš°ì„ )

---

## ğŸ”‘ í•µì‹¬ êµ¬í˜„ íŒŒì¼

### 1. `framework/chunker.py` (245 lines)

**ì±…ì„:**
- tree-sitter íŒŒì‹±
- AST ë…¸ë“œ íƒìƒ‰
- Context ì¶”ì¶œ
- Chunk ìƒì„±

**ì£¼ìš” ë©”ì„œë“œ:**
- `chunk_file()` - ë©”ì¸ entry point
- `_extract_file_context()` - includes/usings ì¶”ì¶œ
- `_create_chunk_from_node()` - AST node â†’ Chunk
- `_get_node_name()` - function/class ì´ë¦„ ì¶”ì¶œ

**ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬:**
```python
import tree_sitter_cpp as ts_cpp
from tree_sitter import Language, Parser
```

---

### 2. `framework/chunk_analyzer.py` (170 lines)

**ì±…ì„:**
- Context + Code ê²°í•©
- LLM ë¶„ì„ í˜¸ì¶œ
- Line number ì¡°ì •

**ì£¼ìš” ë©”ì„œë“œ:**
- `analyze_chunk()` - ë‹¨ì¼ chunk ë¶„ì„
- `_build_analysis_code()` - LLM ì…ë ¥ ìƒì„±
- `_adjust_line_numbers()` - ì¢Œí‘œ ë³€í™˜

**ë³‘ë ¬ ì²˜ë¦¬:**
```python
def analyze_chunks_parallel(self, chunks: List[Chunk]) -> List[AnalysisResult]:
    from concurrent.futures import ThreadPoolExecutor

    with ThreadPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(self.analyze_chunk, chunks))

    return results
```

---

### 3. `framework/result_merger.py` (140 lines)

**ì±…ì„:**
- ì—¬ëŸ¬ chunk ê²°ê³¼ ë³‘í•©
- ì¤‘ë³µ ì œê±°
- ë©”íƒ€ë°ì´í„° ì§‘ê³„

**ì¤‘ë³µ ì œê±° ì „ëµ:**
1. `(line, category)` ìŒìœ¼ë¡œ ê·¸ë£¹í™”
2. ê°™ì€ line+categoryëŠ” í•˜ë‚˜ë§Œ ìœ ì§€
3. severity ë¹„êµ (critical > warning)

---

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì„±

### Token ì‚¬ìš©ëŸ‰

**Without Chunking:**
- 1000 line file = ~3000 tokens (1íšŒ í˜¸ì¶œ)
- Total: 3000 tokens

**With Chunking:**
- 5 chunks Ã— (50 lines context + 200 lines code) = 5 Ã— 750 tokens
- Total: 3750 tokens (25% ì¦ê°€)

**Trade-off:** Tokenì€ ì•½ê°„ ì¦ê°€í•˜ì§€ë§Œ, ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ

---

### ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼

**Sequential:**
- 5 chunks Ã— 8 seconds = 40 seconds

**Parallel (4 workers):**
- max(chunk processing times) â‰ˆ 10-12 seconds

**Speed-up:** ~3-4x faster âœ…

---

### ì •í™•ë„

**ì‹¤í—˜ ê²°ê³¼ (Phase 5):**
- **Without chunking** (129 lines): 11 issues found
- **With chunking** (129 lines): 11 issues found (same!)
- **Accuracy:** 100% maintained âœ…

**ì´ìœ :**
- Contextê°€ ì˜¬ë°”ë¥´ê²Œ prependë¨
- Line number adjustmentê°€ ì •í™•í•¨
- Deduplicationì´ ì œëŒ€ë¡œ ì‘ë™

---

## ğŸ¯ ì‹¤ì œ ì‚¬ìš© ì˜ˆ

### CLIì—ì„œ chunking í™œì„±í™”

```bash
# Enable chunking for large files
python -m cli.main analyze file large_file.cpp --chunk

# Set custom chunk size (default: 200 lines)
python -m cli.main analyze file large_file.cpp --chunk --chunk-size 300

# PR analysis with chunking
python -m cli.main analyze pr --base main --head feature --chunk
```

### Python API

```python
from pathlib import Path
from plugins.production_analyzer import ProductionAnalyzer

analyzer = ProductionAnalyzer(model_name='deepseek-coder:33b-instruct')

# Automatic chunking for files > 300 lines
result = analyzer.analyze_file(
    file_path=Path('large_file.cpp'),
    chunk_mode=True
)

print(f"Found {len(result.issues)} issues")
```

---

## ğŸ› Edge Cases ì²˜ë¦¬

### 1. Parse ì‹¤íŒ¨

**ë¬¸ì œ:** tree-sitterê°€ malformed C++ íŒŒì‹± ëª»í•¨

**í•´ê²°:**
```python
try:
    tree = self.parser.parse(code_bytes)
except Exception as e:
    print(f"Warning: Parse error, falling back to line-based chunking")
    return self._fallback_line_chunking(file_path, code_text)
```

**Fallback:** ë‹¨ìˆœíˆ Nì¤„ì”© ìë¥´ê¸°

---

### 2. Global ì½”ë“œ

**ë¬¸ì œ:** Function/class ë°–ì˜ ì½”ë“œëŠ”?

**í•´ê²°:**
```python
if not chunks:
    # No functions/classes found, return whole file as one chunk
    return self._fallback_line_chunking(file_path, code_text)
```

---

### 3. Nested Classes

**ë¬¸ì œ:** Inner classë„ ë³„ë„ chunkë¡œ?

**í˜„ì¬:** Outer class ì „ì²´ë¥¼ í•˜ë‚˜ì˜ chunkë¡œ ì²˜ë¦¬

**ê°œì„  ì—¬ì§€:** Inner classë¥¼ ë¶„ë¦¬í•˜ëŠ” ë¡œì§ ì¶”ê°€ ê°€ëŠ¥

---

### 4. Templates & Macros

**ë¬¸ì œ:** Template definitionì´ ë§¤ìš° ê¸¸ ë•Œ

**í•´ê²°:**
```python
if self._get_chunk_line_count(chunk) > self.max_chunk_lines:
    # Split large chunk into smaller pieces
    sub_chunks = self._split_large_chunk(chunk)
    chunks.extend(sub_chunks)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### Unit Tests

**tests/test_chunker.py:**
- Chunk ìƒì„± í…ŒìŠ¤íŠ¸
- Context ì¶”ì¶œ í…ŒìŠ¤íŠ¸
- Line number ê³„ì‚° í…ŒìŠ¤íŠ¸
- Edge case í…ŒìŠ¤íŠ¸

**tests/test_chunk_analyzer.py:**
- Line number ì¡°ì • í…ŒìŠ¤íŠ¸
- ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

**tests/test_result_merger.py:**
- Deduplication í…ŒìŠ¤íŠ¸
- Severity ë¹„êµ í…ŒìŠ¤íŠ¸

### Integration Tests

**tests/test_integration_chunking.py:**
- End-to-end chunking workflow
- 129 line file (without vs. with chunking)
- 645 line file (large file test)

**ê²°ê³¼:**
- 83/84 tests passing (98.8%)
- ë‹¨ 1ê°œ ì‹¤íŒ¨: timeout (645 lines, 90ì´ˆ ì œí•œ)

---

## ğŸš€ Demo ì‹¤í–‰

```bash
cd /home/baum/workspace/claude-home/cpp-llm-reviewer

# Run the demo
python3 demo_ast_chunking.py

# ì¶œë ¥: ê° chunkê°€ ì–´ë–»ê²Œ ìƒì„±ë˜ê³  LLMì— ì „ë‹¬ë˜ëŠ”ì§€ í™•ì¸
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **tree-sitter ë¬¸ì„œ:** https://tree-sitter.github.io/tree-sitter/
- **tree-sitter-cpp:** https://github.com/tree-sitter/tree-sitter-cpp
- **Phase 5 ì™„ë£Œ ë¬¸ì„œ:** [docs/phases/PHASE5_COMPLETE.md](../phases/PHASE5_COMPLETE.md)
- **Architecture ë¬¸ì„œ:** [ARCHITECTURE.md](ARCHITECTURE.md)

---

## âœ¨ ìš”ì•½

### AST Chunkingì´ë€?

**tree-sitter**ë¡œ C++ ì½”ë“œë¥¼ íŒŒì‹±í•´ì„œ **ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„**(function, class)ë¡œ ë‚˜ëˆ„ê³ , ê° chunkì— **contextë¥¼ ì¶”ê°€**í•´ì„œ LLMì´ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” ê¸°ìˆ .

### ì™œ í•„ìš”í•œê°€?

ëŒ€ìš©ëŸ‰ íŒŒì¼(300+ lines)ì€ LLM token limitì„ ì´ˆê³¼í•˜ê±°ë‚˜ ë¶„ì„ ì •í™•ë„ê°€ ë–¨ì–´ì§. Chunkingìœ¼ë¡œ í•´ê²°!

### ì–´ë–»ê²Œ ë™ì‘í•˜ë‚˜?

1. tree-sitterë¡œ AST íŒŒì‹±
2. Context(#includes, usings) ì¶”ì¶œ
3. Function/Classë³„ë¡œ chunk ìƒì„±
4. Context + Codeë¥¼ LLMì— ì „ë‹¬
5. Line number ì¡°ì •
6. ê²°ê³¼ ë³‘í•© & ì¤‘ë³µ ì œê±°

### ì„±ëŠ¥ì€?

- **Token:** 25% ì¦ê°€ (acceptable)
- **ì†ë„:** 3-4x ë¹ ë¦„ (ë³‘ë ¬ ì²˜ë¦¬)
- **ì •í™•ë„:** 100% ìœ ì§€ âœ…

### ê²°ë¡ 

Production-ready! ğŸ‰
