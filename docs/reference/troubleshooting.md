# Chapter 09: ë¬¸ì œ í•´ê²° (Troubleshooting)

---

## ğŸ” ë¬¸ì œ ì§„ë‹¨ ì²´í¬ë¦¬ìŠ¤íŠ¸

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒ ìˆœì„œë¡œ í™•ì¸í•˜ì„¸ìš”:

1. â˜ Ollama ì‹¤í–‰ ì¤‘ì¸ê°€? (`ollama list`)
2. â˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë˜ì—ˆëŠ”ê°€? (`ollama list | grep deepseek`)
3. â˜ ê°€ìƒí™˜ê²½ í™œì„±í™”ë˜ì—ˆëŠ”ê°€? (`which python`)
4. â˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë˜ì—ˆëŠ”ê°€? (`pip list | grep ollama`)
5. â˜ ë””ìŠ¤í¬ ê³µê°„ ì¶©ë¶„í•œê°€? (`df -h`)
6. â˜ ë©”ëª¨ë¦¬ ì¶©ë¶„í•œê°€? (`free -h`)

---

## ì„¤ì¹˜ ë¬¸ì œ

### âŒ "ollama: command not found"

**ì¦ìƒ**:
```bash
$ ollama list
bash: ollama: command not found
```

**ì›ì¸**: Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ PATHì— ì—†ìŒ

**í•´ê²°**:
```bash
# ì¬ì„¤ì¹˜
curl https://ollama.ai/install.sh | sh

# PATH í™•ì¸
echo $PATH

# ìˆ˜ë™ PATH ì¶”ê°€ (í•„ìš”ì‹œ)
export PATH=$PATH:/usr/local/bin
echo 'export PATH=$PATH:/usr/local/bin' >> ~/.bashrc
```

---

### âŒ "ModuleNotFoundError: No module named 'framework'"

**ì¦ìƒ**:
```bash
$ python -m cli.main analyze file test.cpp
ModuleNotFoundError: No module named 'framework'
```

**ì›ì¸**: íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
# 1. ê°€ìƒí™˜ê²½ í™•ì¸
which python
# ì¶œë ¥: /path/to/venv/bin/python (ê°€ìƒí™˜ê²½)
# ì¶œë ¥: /usr/bin/python (ì‹œìŠ¤í…œ) â† ë¬¸ì œ!

# 2. ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# 3. íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜
pip install -e .
```

---

### âŒ "Model not found: deepseek-coder:33b-instruct"

**ì¦ìƒ**:
```
Error: model 'deepseek-coder:33b-instruct' not available in Ollama
```

**ì›ì¸**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì•ˆ ë¨

**í•´ê²°**:
```bash
# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull deepseek-coder:33b-instruct

# ë‹¤ìš´ë¡œë“œ í™•ì¸
ollama list

# ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ)
# ë” ì‘ì€ ëª¨ë¸ ì‹œë„
ollama pull qwen2.5-coder:14b
```

---

## ì‹¤í–‰ ë¬¸ì œ

### âŒ "Cannot connect to Ollama"

**ì¦ìƒ**:
```
ConnectionError: Cannot connect to Ollama at localhost:11434
```

**ì›ì¸**: Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
# Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve &

# í™•ì¸
curl http://localhost:11434/api/tags
```

---

### âŒ "Out of Memory (OOM)"

**ì¦ìƒ**:
```
Error: model requires more memory than available
Killed
```

**ì›ì¸**: 33B ëª¨ë¸ì€ ìµœì†Œ 16GB RAM í•„ìš”

**í•´ê²° ì˜µì…˜ 1**: ë” ì‘ì€ ëª¨ë¸
```bash
ollama pull qwen2.5-coder:14b  # 8GB RAMìœ¼ë¡œ ê°€ëŠ¥
python -m cli.main analyze file test.cpp --model qwen2.5-coder:14b
```

**í•´ê²° ì˜µì…˜ 2**: Swap ë©”ëª¨ë¦¬ ëŠ˜ë¦¬ê¸° (Linux)
```bash
# 16GB swap ìƒì„±
sudo fallocate -l 16G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# ì˜êµ¬ ì ìš©
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

**í•´ê²° ì˜µì…˜ 3**: GPU ì‚¬ìš©
```bash
# GPU í™•ì¸
nvidia-smi

# Ollamaê°€ ìë™ìœ¼ë¡œ GPU ê°ì§€
# GPU VRAM ì‚¬ìš© â†’ ì‹œìŠ¤í…œ RAM ì ˆì•½
```

---

### âŒ ë¶„ì„ì´ ë„ˆë¬´ ëŠë¦¼

**ì¦ìƒ**: íŒŒì¼ë‹¹ 5ë¶„ ì´ìƒ ì†Œìš”

**ì›ì¸**: GPU ë¯¸ì‚¬ìš© ë˜ëŠ” ëª¨ë¸ì´ ë„ˆë¬´ í¼

**í•´ê²°**:
```bash
# 1. GPU ì‚¬ìš© í™•ì¸
nvidia-smi  # GPU í”„ë¡œì„¸ìŠ¤ì— ollamaê°€ ë³´ì—¬ì•¼ í•¨

# 2. ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
python -m cli.main analyze file test.cpp --model qwen2.5-coder:14b

# 3. ì²­í‚¹ ì‚¬ìš© (ëŒ€ìš©ëŸ‰ íŒŒì¼)
python -m cli.main analyze file large.cpp --chunk

# 4. CPU ì½”ì–´ í™•ì¸
nproc  # ì½”ì–´ ìˆ˜ í™•ì¸
# ë³‘ë ¬ ì›Œì»¤ ìˆ˜ë¥¼ ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì • (ì½”ë“œ ìˆ˜ì • í•„ìš”)
```

---

## ê²°ê³¼ í’ˆì§ˆ ë¬¸ì œ

### âŒ False Positiveê°€ ë„ˆë¬´ ë§ìŒ

**ì¦ìƒ**: ë²„ê·¸ê°€ ì•„ë‹Œë° ë²„ê·¸ë¡œ íƒì§€ë¨

**í•´ê²°**:
```bash
# 1. Hybrid ê¸°ë²• ì‚¬ìš© (ì •ë°€ë„ í–¥ìƒ)
# plugins/production_analyzer.py ìˆ˜ì •
technique_config = {'technique_name': 'hybrid'}

# 2. ì‹ ë¢°ë„ í•„í„°ë§
# ê²°ê³¼ì—ì„œ confidence < 0.7ì¸ ì´ìŠˆ ì œì™¸

# 3. Ground truthì— false positive ì˜ˆì‹œ ì¶”ê°€
# experiments/ground_truth/cpp/example_XXX.json
```

---

### âŒ ë²„ê·¸ë¥¼ ëª» ì°¾ìŒ (False Negative)

**ì¦ìƒ**: ëª…ë°±í•œ ë²„ê·¸ì¸ë° íƒì§€í•˜ì§€ ëª»í•¨

**í•´ê²°**:
```bash
# 1. ë” í° ëª¨ë¸ ì‹œë„
python -m cli.main analyze file test.cpp --model deepseek-coder:33b-instruct

# 2. Hybrid ê¸°ë²• ì‚¬ìš©
# ë” ë§ì€ passë¡œ íƒì§€ í™•ë¥  ì¦ê°€

# 3. Ground truthì— ë†“ì¹œ ë²„ê·¸ ì˜ˆì‹œ ì¶”ê°€
# ê·¸ë¦¬ê³  ì¬ì‹¤í—˜
python -m cli.main experiment run --config experiments/configs/few_shot_5.yml
```

---

### âŒ Modern-cpp ì´ìŠˆë¥¼ ëª» ì°¾ìŒ

**ì¦ìƒ**: ìŠ¤ë§ˆíŠ¸ í¬ì¸í„° ì œì•ˆ ë“±ì´ ë‚˜ì˜¤ì§€ ì•ŠìŒ

**ì›ì¸**: Modern-cppëŠ” Few-shotìœ¼ë¡œ íƒì§€ ì–´ë ¤ì›€ (F1: 0.000)

**í•´ê²°**:
```bash
# Chain-of-thought ê¸°ë²• ì‚¬ìš© (F1: 0.727)
# ë˜ëŠ” Hybrid ê¸°ë²•
```

---

## Git/PR ë¬¸ì œ

### âŒ "Not a git repository"

**ì¦ìƒ**:
```
Error: Not a git repository
```

**í•´ê²°**:
```bash
# Git ì €ì¥ì†Œ ì´ˆê¸°í™”
git init
git add .
git commit -m "Initial commit"

# ë˜ëŠ” ì˜¬ë°”ë¥¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
cd /path/to/git/repo
```

---

### âŒ "No C++ files changed"

**ì¦ìƒ**:
```
Analyzed 0 files
No issues found
```

**ì›ì¸**: PRì— C++ íŒŒì¼ ë³€ê²½ì´ ì—†ìŒ

**í•´ê²°**:
```bash
# ë³€ê²½ëœ íŒŒì¼ í™•ì¸
git diff --name-only main...feature-branch

# C++ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
git diff --name-only main...feature-branch | grep -E '\.(cpp|h|hpp)$'
```

---

## ì‹¤í—˜ ì‹¤í–‰ ë¬¸ì œ

### âŒ "Ground truth file not found"

**ì¦ìƒ**:
```
FileNotFoundError: experiments/ground_truth/cpp/example_001.json
```

**í•´ê²°**:
```bash
# Ground truth ë””ë ‰í† ë¦¬ í™•ì¸
ls experiments/ground_truth/cpp/

# íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
# ë˜ëŠ” ì˜¬ë°”ë¥¸ ê²½ë¡œì—ì„œ ì‹¤í–‰
cd /path/to/llm-code-reviewer
```

---

### âŒ "Experiment failed: JSON parsing error"

**ì¦ìƒ**:
```
JSONDecodeError: Expecting property name enclosed in double quotes
```

**ì›ì¸**: LLMì´ ì˜ëª»ëœ í˜•ì‹ì˜ JSON ë°˜í™˜

**í•´ê²°**:
```bash
# 1. í”„ë¡¬í”„íŠ¸ ë¡œê·¸ í™•ì¸
cat experiments/runs/<run-id>/*_prompts.jsonl | tail -20

# 2. ì˜¨ë„(temperature) ë‚®ì¶”ê¸°
# experiments/configs/your_config.yml
technique_params:
  temperature: 0.0  # ë” ê²°ì •ì ì¸ ì¶œë ¥

# 3. ì¬ì‹œë„
python -m cli.main experiment run --config experiments/configs/few_shot_5.yml
```

---

## ì¼ë°˜ì ì¸ íŒ

### ë¡œê·¸ í™•ì¸

```bash
# ìƒì„¸ ë¡œê·¸ ì¶œë ¥
python -m cli.main analyze file test.cpp --verbose

# í”„ë¡¬í”„íŠ¸ í™•ì¸ (ë””ë²„ê¹…)
# framework/ollama_client.pyì— print() ì¶”ê°€
```

### í™˜ê²½ ì´ˆê¸°í™”

ëª¨ë“  ê²ƒì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘:

```bash
# 1. ê°€ìƒí™˜ê²½ ì‚­ì œ
rm -rf venv

# 2. ê°€ìƒí™˜ê²½ ì¬ìƒì„±
python -m venv venv
source venv/bin/activate

# 3. ì¬ì„¤ì¹˜
pip install -e .

# 4. Ollama ì¬ì‹œì‘
pkill ollama
ollama serve &

# 5. ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ
ollama pull deepseek-coder:33b-instruct
```

---

## ë„ì›€ ë°›ê¸°

ìœ„ ë°©ë²•ìœ¼ë¡œ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´:

1. **GitHub Issues** í™•ì¸
   - ìœ ì‚¬í•œ ë¬¸ì œê°€ ë³´ê³ ë˜ì—ˆëŠ”ì§€ ê²€ìƒ‰

2. **ë¡œê·¸ í¬í•¨í•´ì„œ ì´ìŠˆ ìƒì„±**
   ```bash
   # ì¬í˜„ ê°€ëŠ¥í•œ ìµœì†Œ ì˜ˆì œ í¬í•¨
   # ì—ëŸ¬ ë©”ì‹œì§€ ì „ì²´ ë³µì‚¬
   # í™˜ê²½ ì •ë³´ í¬í•¨ (OS, Python ë²„ì „, GPU ë“±)
   ```

3. **Slackì—ì„œ ë¬¸ì˜**
   - #llm-code-reviewer ì±„ë„

---

**ì´ì „**: [Chapter 08: FAQ](08-faq.md) â†
**ëª©ì°¨ë¡œ**: [Index](00-INDEX.md) â†‘
